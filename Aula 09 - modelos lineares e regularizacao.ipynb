{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Modelos lineares e regularização"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos começar importando as bibliotecas de costume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from pprint import pprint\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import PolynomialFeatures, StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## O que acontece se duas colunas forem iguais?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 1, 7, 7],\n",
       "       [1, 2, 8, 3],\n",
       "       [1, 3, 7, 3],\n",
       "       [1, 4, 6, 3],\n",
       "       [1, 5, 5, 3],\n",
       "       [1, 6, 4, 3],\n",
       "       [1, 7, 3, 3],\n",
       "       [1, 8, 2, 3]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = np.array(\n",
    "    [\n",
    "        [1,1,7,7],\n",
    "        [1,2,8,3],\n",
    "        [1,3,7,3],\n",
    "        [1,4,6,3],\n",
    "        [1,5,5,3],\n",
    "        [1,6,4,3],\n",
    "        [1,7,3,3],\n",
    "        [1,8,2,3]\n",
    "\n",
    "    ]\n",
    ")\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  8,  36,  42,  28],\n",
       "       [ 36, 204, 154, 112],\n",
       "       [ 42, 154, 252, 154],\n",
       "       [ 28, 112, 154, 112]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "XtX= X.T @ X\n",
    "XtX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linalg.det(XtX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "LinAlgError",
     "evalue": "Singular matrix",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mLinAlgError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Asus\\Documents\\Matérias\\Machine Learning\\Machine-Learning\\Aula 09 - modelos lineares e regularizacao.ipynb Cell 8\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Asus/Documents/Mat%C3%A9rias/Machine%20Learning/Machine-Learning/Aula%2009%20-%20modelos%20lineares%20e%20regularizacao.ipynb#X65sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m np\u001b[39m.\u001b[39;49mlinalg\u001b[39m.\u001b[39;49minv(XtX)\n",
      "File \u001b[1;32m<__array_function__ internals>:200\u001b[0m, in \u001b[0;36minv\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\Asus\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\linalg\\linalg.py:538\u001b[0m, in \u001b[0;36minv\u001b[1;34m(a)\u001b[0m\n\u001b[0;32m    536\u001b[0m signature \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mD->D\u001b[39m\u001b[39m'\u001b[39m \u001b[39mif\u001b[39;00m isComplexType(t) \u001b[39melse\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39md->d\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m    537\u001b[0m extobj \u001b[39m=\u001b[39m get_linalg_error_extobj(_raise_linalgerror_singular)\n\u001b[1;32m--> 538\u001b[0m ainv \u001b[39m=\u001b[39m _umath_linalg\u001b[39m.\u001b[39;49minv(a, signature\u001b[39m=\u001b[39;49msignature, extobj\u001b[39m=\u001b[39;49mextobj)\n\u001b[0;32m    539\u001b[0m \u001b[39mreturn\u001b[39;00m wrap(ainv\u001b[39m.\u001b[39mastype(result_t, copy\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m))\n",
      "File \u001b[1;32mc:\\Users\\Asus\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\linalg\\linalg.py:89\u001b[0m, in \u001b[0;36m_raise_linalgerror_singular\u001b[1;34m(err, flag)\u001b[0m\n\u001b[0;32m     88\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_raise_linalgerror_singular\u001b[39m(err, flag):\n\u001b[1;32m---> 89\u001b[0m     \u001b[39mraise\u001b[39;00m LinAlgError(\u001b[39m\"\u001b[39m\u001b[39mSingular matrix\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;31mLinAlgError\u001b[0m: Singular matrix"
     ]
    }
   ],
   "source": [
    "np.linalg.inv(XtX)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos tambem inicializar o gerador de números aleatórios do Numpy para garantir a reproducibilidade dos nossos resultados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RAND_SEED = 42\n",
    "np.random.seed(RAND_SEED)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora vamos gerar um conjunto de valores experimentais $(x,y)$ aleatórios da seguinte forma:\n",
    "\n",
    "- Os valores de $x$ são sorteados uniformemente entre $-3$ e $3$\n",
    "- Os valores de $y$ são obtidos em dois passos:\n",
    "    - Calculamos $y_{\\text{clean}}$ como função de $x$: $y_{\\text{clean}} = \\frac{1}{2} x^2 + x + 2$\n",
    "    - Calculamos o valor final de $y$ como sendo $y = y_{\\text{clean}} + \\varepsilon$ onde $\\varepsilon \\sim N(0, 1)$ é uma variável aleatória normal de média zero e desvio padrão $1$.\n",
    "\n",
    "Vamos usar esses valores experimentais para continuar nossa exploração sobre modelos lineares."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Numero de pontos a serem gerados.\n",
    "m = 50\n",
    "\n",
    "# Valores de x, na forma de uma matriz-coluna m por 1.\n",
    "X = 6 * np.random.rand(m, 1) - 3\n",
    "\n",
    "# Valores de y sem ruido, que são uma função quadrática de x.\n",
    "y_clean = 0.5 * X**2 + X + 2\n",
    "\n",
    "# Adicionando ruido à y.\n",
    "y = y_clean + np.random.randn(m, 1)\n",
    "\n",
    "# Vamos ver como ficou.\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(X, y, \"b.\", linewidth=3)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nosso objetivo será ajustar vários modelos lineares polinomiais aos dados, com diferentes graus de polinômio, e compará-los:\n",
    "\n",
    "- Modelo linear de grau $1$: $\\hat{y} = \\theta_0 + \\theta_1 x$\n",
    "- Modelo linear de grau $2$: $\\hat{y} = \\theta_0 + \\theta_1 x + \\theta_2 x^2$\n",
    "- Modelo linear de grau $30$: $\\hat{y} = \\theta_0 + \\theta_1 x + \\cdots + \\theta_{30} x^{30}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def experimento(X, y, degree):\n",
    "    # Cria a pipeline.\n",
    "    pipe = Pipeline([\n",
    "        (\"poly_features\",\n",
    "         PolynomialFeatures(\n",
    "             degree=degree,\n",
    "             include_bias=False,\n",
    "         )),\n",
    "        (\"std_scaler\", StandardScaler()),\n",
    "        (\"lin_reg\", LinearRegression()),\n",
    "    ])\n",
    "\n",
    "    # Ajusta a pipeline nos dados de treinamento.\n",
    "    pipe.fit(X, y)\n",
    "\n",
    "    # Imprime os parametros obtidos no ajuste de modelo.\n",
    "    def print_title(title):\n",
    "        msg = f'Parâmetros do {title}'\n",
    "        print(msg)\n",
    "        print('-' * len(msg))\n",
    "\n",
    "    def print_array(name, arr):\n",
    "        print(name)\n",
    "        pprint(arr)\n",
    "        print()\n",
    "\n",
    "    scaler = pipe.named_steps['std_scaler']\n",
    "    print_title('StandardScaler')\n",
    "    print_array('mean:', scaler.mean_)\n",
    "    print_array('scale:', scaler.scale_)\n",
    "\n",
    "    model = pipe.named_steps['lin_reg']\n",
    "    print_title('modelo linear')\n",
    "    print_array('theta_0:', model.intercept_)\n",
    "    print_array('Demais coeficientes theta_i:', model.coef_)\n",
    "\n",
    "    # Coordenadas de teste para visualizar as predições efetuadas\n",
    "    # pelo modelo ajustado.\n",
    "    X_test = np.linspace(-3, 3, num=100).T\n",
    "\n",
    "    # Calcula as predições da pipeline nos dados de teste.\n",
    "    y_test = pipe.predict(X_test.reshape(-1, 1))\n",
    "\n",
    "    # Vamos ver como ficou.\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.plot(X, y, \"b.\", linewidth=3)\n",
    "    plt.plot(X_test, y_test, 'r-', label=f'grau {degree}')\n",
    "    plt.xlabel('$X$')\n",
    "    plt.ylabel('$y$', rotation=0)\n",
    "    plt.axis([-3, 3, 0, 10])\n",
    "    plt.title(f'Modelo de grau ${degree}$')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No primeiro experimento, vamos usar um modelo linear de grau $1$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Experimento 1: grau baixo.\n",
    "experimento(X, y, degree=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No segundo experimento vamos usar um modelo polinomial de grau $2$. Este é o modelo que esperamos que atinja nosso *benchmark* de parâmetros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experimento 2: grau adequado.\n",
    "experimento(X, y, degree=2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No terceiro modelo vamos exagerar no grau do modelo polinomial, para ver o que acontece."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experimento 3: grau exagerado.\n",
    "experimento(X, y, degree=30)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regularização"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conforme vimos acima, um modelo muito complexo pode sofrer do problema de *overfitting*. Uma forma de domar a complexidade do modelo é limitar o número de *features*. Por exemplo, usando *features* polinomiais, podemos limitar o grau do polinômio.\n",
    "\n",
    "Outra forma de tratar a complexidade dos modelos é através da estratégia de *regularização*. Trata-se do seguinte:\n",
    "\n",
    "1. Definimos métricas diferentes de erro para a fase de treinamento e a fase de testes.\n",
    "    - Na fase de treinamento usamos uma *métrica regularizada*\n",
    "    - Na fase de testes usamos uma métrica convencional\n",
    "    \n",
    "2. A métrica regularizada funciona assim: trata-se da métrica convencional acrescida de um termo que *penaliza a complexidade do modelo*.\n",
    "\n",
    "Com isso favorecemos modelos de complexidade reduzida, mesmo que o grau do polinômio seja alto."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ridge, Lasso e ElasticNet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nestas modalidades de regularização adicionamos uma penalidade para a norma do vetor de parâmetros:\n",
    "\n",
    "- Ridge: a penalidade é proporcional à norma $L_2$ do vetor de parâmetros.\n",
    "\n",
    "- Lasso: a penalidade é proporcional à norma $L_1$ do vetor de parâmetros.\n",
    "\n",
    "- ElasticNet: uma soma ponderada de penalidades proporcionais às normas $L_1$ e $L_2$ do vetor de parâmetros é aplicada.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Atividade:** O material do livro-texto, na seção \"Regularized Linear Models\" está muito bom, estude este material e responda:\n",
    "\n",
    "- Qual a diferença entre *ridge regression*, *lasso regression*, e *elastic net*?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**R:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Eis aqui uma demonstração das várias regularizações:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import ElasticNet, Lasso, Ridge\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "def outro_experimento(msg, pipeline, X_train, y_train, X_test, y_test):\n",
    "    pipeline.fit(X_train, y_train)\n",
    "    y_pred = pipeline.predict(X_test)\n",
    "    RMSE = np.sqrt(mean_squared_error(y_pred, y_test))\n",
    "\n",
    "    model = pipeline.named_steps['lin_reg']\n",
    "    print(f'{msg}:')\n",
    "    print(f'intercept = {model.intercept_}')\n",
    "    print(f'coefs = {model.coef_}')\n",
    "    print(f'RMSE: {RMSE}')\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X,\n",
    "    y,\n",
    "    test_size=0.2,\n",
    "    random_state=RAND_SEED,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_linear_regressor_pipeline(degree):\n",
    "    pipe = Pipeline([\n",
    "        (\"poly_features\",\n",
    "         PolynomialFeatures(\n",
    "             degree=degree,\n",
    "             include_bias=False,\n",
    "         )),\n",
    "        (\"std_scaler\", StandardScaler()),\n",
    "        (\"lin_reg\", LinearRegression()),\n",
    "    ])\n",
    "    return pipe\n",
    "\n",
    "\n",
    "poly_reg_1 = get_linear_regressor_pipeline(degree=1)\n",
    "poly_reg_2 = get_linear_regressor_pipeline(degree=2)\n",
    "poly_reg_30 = get_linear_regressor_pipeline(degree=30)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testa o fit do poly_reg_1.\n",
    "outro_experimento(\n",
    "    'Fit de grau 1, sem regularização',\n",
    "    poly_reg_1,\n",
    "    X_train,\n",
    "    y_train,\n",
    "    X_test,\n",
    "    y_test,\n",
    ")\n",
    "\n",
    "# Testa o fit do poly_reg_2.\n",
    "outro_experimento(\n",
    "    'Fit de grau 2, sem regularização',\n",
    "    poly_reg_2,\n",
    "    X_train,\n",
    "    y_train,\n",
    "    X_test,\n",
    "    y_test,\n",
    ")\n",
    "\n",
    "# Testa o fit do poly_reg_30.\n",
    "outro_experimento(\n",
    "    'Fit de grau 30, sem regularização',\n",
    "    poly_reg_30,\n",
    "    X_train,\n",
    "    y_train,\n",
    "    X_test,\n",
    "    y_test,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Coeficiente de regularização para os experimentos a seguir.\n",
    "alpha = 1e-1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testa o fit da regularização ridge.\n",
    "poly_reg_ridge = Pipeline([\n",
    "    (\"poly_features\", PolynomialFeatures(degree=30, include_bias=False)),\n",
    "    (\"std_scaler\", StandardScaler()),\n",
    "    (\"lin_reg\", Ridge(alpha=alpha)),\n",
    "])\n",
    "outro_experimento(\n",
    "    'Fit de grau 30, regularização ridge',\n",
    "    poly_reg_ridge,\n",
    "    X_train,\n",
    "    y_train,\n",
    "    X_test,\n",
    "    y_test,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test o fit da regularização lasso.\n",
    "poly_reg_lasso = Pipeline([\n",
    "    (\"poly_features\", PolynomialFeatures(degree=30, include_bias=False)),\n",
    "    (\"std_scaler\", StandardScaler()),\n",
    "    (\"lin_reg\", Lasso(alpha=alpha)),\n",
    "])\n",
    "outro_experimento(\n",
    "    'Fit de grau 30, regularização lasso',\n",
    "    poly_reg_lasso,\n",
    "    X_train,\n",
    "    y_train,\n",
    "    X_test,\n",
    "    y_test,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test o fit da regularização elastic net.\n",
    "poly_reg_elasticnet = Pipeline([\n",
    "    (\"poly_features\", PolynomialFeatures(degree=30, include_bias=False)),\n",
    "    (\"std_scaler\", StandardScaler()),\n",
    "    (\"lin_reg\", ElasticNet(alpha=alpha, l1_ratio=0.5, random_state=RAND_SEED)),\n",
    "])\n",
    "outro_experimento(\n",
    "    'Fit de grau 30, regularização elastic net',\n",
    "    poly_reg_elasticnet,\n",
    "    X_train,\n",
    "    y_train,\n",
    "    X_test,\n",
    "    y_test,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Atividade:** \n",
    "\n",
    "- Coloque o $\\alpha$ bem alto, o que acontece?\n",
    "\n",
    "- Coloque o $\\alpha$ muito baixo, o que acontece?\n",
    "\n",
    "- Explique a diferença observada entre sem regularização / regularização ridge / regularização lasso / regularização elastic net."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**R:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regularização por parada prematura (*early stopping*)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Um modo bizarro de regularização é o chamado *early stopping*.\n",
    "\n",
    "Considere o algoritmo de treinamento *gradient descent*. Quanto mais iteramos neste algoritmo (em machine learning, as iterações são chamadas **epochs**), menor o *erro de treinamento*. Porém, se acompanharmos o *erro de validação* à cada epoch, vemos que este decresce com as epochs até um certo ponto, *e depois começa a subir novamente*!\n",
    "\n",
    "<img src=\"early_stopping_plot.png\" alt=\"Regularização por parada prematura\" style=\"width: 600px;\"/>\n",
    "\n",
    "\n",
    "**Atividade:** Por que isso acontece?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**R:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Continuando:\n",
    "\n",
    "Portanto, se detectarmos que o erro de validação está realmente subindo, podemos parar com o processo de treinamento e adotar o modelo resultante como o nosso modelo treinado! Esta estratégia de *parada prematura* (early stopping) é surpreendentemente simples e eficaz!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interpretabilidade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = PolynomialFeatures(degree=5, include_bias=True)\n",
    "Xb = pipe.fit_transform(X)\n",
    "\n",
    "model = sm.OLS(y, Xb)\n",
    "results = model.fit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Atividade:**\n",
    "\n",
    "Experimente com diferentes valores para o grau do polinômio: 1, 2, 5, 10. Relate o que você observou"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**R:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "toc-autonumbering": false,
  "toc-showcode": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
