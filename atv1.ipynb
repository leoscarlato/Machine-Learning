{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Média -> $\\frac{1}{m} \\sum_{i=1}^{m}$\n",
    "\n",
    "Erro => $(h(x_i) - y_i)^2$\n",
    "\n",
    "Erro quadrático médio -> $$ \\sqrt{\\frac{1}{m} \\sum_{i=1}^{m}\\left(h(x_i) - y_i\\right)^{2}}$$\n",
    "\n",
    "\n",
    "è muito comum a estratégia de:\n",
    "\n",
    "- definir uma perda por amostra\n",
    "\n",
    "- definir a perda total como a média das perdas individuais"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**RMSE** (Root Mean Squared Error) é uma medida de erro absoluto que eleva os desvios ao quadrado para impedir que os desvios positivos e negativos se cancelem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nomenclatura\n",
    "\n",
    "Dataset -> $D = {({(x_1, y_1),(x_2, y_2),(x_3, y_3),...,(x_m, y_m)})}$\n",
    "\n",
    "$m$ -> Número de amostras\n",
    "\n",
    "$n$ -> Número de features\n",
    "\n",
    "Features -> $X = ({x_1,x_2,x_3,...,x_m})$\n",
    "\n",
    "Target -> $Y = ({y_1,y_2,y_3,...,y_m})$\n",
    "\n",
    "Previsões -> $Y^ = ({y_1,y_2,y_3,...,y_m})$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Iniciando a SEED da função random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_SEED = 42\n",
    "np.random.seed(RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lendo o .csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'housing.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 6\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mload_housing_data\u001b[39m(housing_file\u001b[39m=\u001b[39mHOUSING_FILE):\n\u001b[0;32m      4\u001b[0m     \u001b[39mreturn\u001b[39;00m pd\u001b[39m.\u001b[39mread_csv(housing_file)\n\u001b[1;32m----> 6\u001b[0m housing \u001b[39m=\u001b[39m load_housing_data()\n",
      "Cell \u001b[1;32mIn[3], line 4\u001b[0m, in \u001b[0;36mload_housing_data\u001b[1;34m(housing_file)\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mload_housing_data\u001b[39m(housing_file\u001b[39m=\u001b[39mHOUSING_FILE):\n\u001b[1;32m----> 4\u001b[0m     \u001b[39mreturn\u001b[39;00m pd\u001b[39m.\u001b[39;49mread_csv(housing_file)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\io\\parsers\\readers.py:912\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m    899\u001b[0m kwds_defaults \u001b[39m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m    900\u001b[0m     dialect,\n\u001b[0;32m    901\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    908\u001b[0m     dtype_backend\u001b[39m=\u001b[39mdtype_backend,\n\u001b[0;32m    909\u001b[0m )\n\u001b[0;32m    910\u001b[0m kwds\u001b[39m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m--> 912\u001b[0m \u001b[39mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\io\\parsers\\readers.py:577\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    574\u001b[0m _validate_names(kwds\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mnames\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m))\n\u001b[0;32m    576\u001b[0m \u001b[39m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 577\u001b[0m parser \u001b[39m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[0;32m    579\u001b[0m \u001b[39mif\u001b[39;00m chunksize \u001b[39mor\u001b[39;00m iterator:\n\u001b[0;32m    580\u001b[0m     \u001b[39mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\io\\parsers\\readers.py:1407\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1404\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptions[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m kwds[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[0;32m   1406\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles: IOHandles \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m-> 1407\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_make_engine(f, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mengine)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\io\\parsers\\readers.py:1661\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1659\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m mode:\n\u001b[0;32m   1660\u001b[0m         mode \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m-> 1661\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39m=\u001b[39m get_handle(\n\u001b[0;32m   1662\u001b[0m     f,\n\u001b[0;32m   1663\u001b[0m     mode,\n\u001b[0;32m   1664\u001b[0m     encoding\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mencoding\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[0;32m   1665\u001b[0m     compression\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mcompression\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[0;32m   1666\u001b[0m     memory_map\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mmemory_map\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mFalse\u001b[39;49;00m),\n\u001b[0;32m   1667\u001b[0m     is_text\u001b[39m=\u001b[39;49mis_text,\n\u001b[0;32m   1668\u001b[0m     errors\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mencoding_errors\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mstrict\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[0;32m   1669\u001b[0m     storage_options\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mstorage_options\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[0;32m   1670\u001b[0m )\n\u001b[0;32m   1671\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m   1672\u001b[0m f \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles\u001b[39m.\u001b[39mhandle\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\io\\common.py:859\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    854\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(handle, \u001b[39mstr\u001b[39m):\n\u001b[0;32m    855\u001b[0m     \u001b[39m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    856\u001b[0m     \u001b[39m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    857\u001b[0m     \u001b[39mif\u001b[39;00m ioargs\u001b[39m.\u001b[39mencoding \u001b[39mand\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m ioargs\u001b[39m.\u001b[39mmode:\n\u001b[0;32m    858\u001b[0m         \u001b[39m# Encoding\u001b[39;00m\n\u001b[1;32m--> 859\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39;49m(\n\u001b[0;32m    860\u001b[0m             handle,\n\u001b[0;32m    861\u001b[0m             ioargs\u001b[39m.\u001b[39;49mmode,\n\u001b[0;32m    862\u001b[0m             encoding\u001b[39m=\u001b[39;49mioargs\u001b[39m.\u001b[39;49mencoding,\n\u001b[0;32m    863\u001b[0m             errors\u001b[39m=\u001b[39;49merrors,\n\u001b[0;32m    864\u001b[0m             newline\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m    865\u001b[0m         )\n\u001b[0;32m    866\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    867\u001b[0m         \u001b[39m# Binary mode\u001b[39;00m\n\u001b[0;32m    868\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39m(handle, ioargs\u001b[39m.\u001b[39mmode)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'housing.csv'"
     ]
    }
   ],
   "source": [
    "HOUSING_FILE = 'housing.csv'\n",
    "\n",
    "def load_housing_data(housing_file=HOUSING_FILE):\n",
    "    return pd.read_csv(housing_file)\n",
    "\n",
    "housing = load_housing_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Separação entre dados de teste e de treinamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_set, test_set = train_test_split(housing, test_size=0.2, random_state=RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Código que insere uma nova coluna representando as faixas de renda, e, após isso, realizando uma separação estratificada para garantir representação proporcional das faixas de renda nos DataSets de treinamento e teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constroi uma coluna nova com categorias de renda fictícias.\n",
    "housing['income_cat'] = np.ceil(housing['median_income'] / 1.5)\n",
    "housing['income_cat'].where(housing['income_cat'] < 5, 5.0, inplace=True)\n",
    "\n",
    "\n",
    "# Divide, de modo estratificado, o conjunto de dados.\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "split = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=RANDOM_SEED)\n",
    "for train_index, test_index in split.split(housing, housing[\"income_cat\"]):\n",
    "    strat_train_set = housing.loc[train_index]\n",
    "    strat_test_set = housing.loc[test_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "income_cat\n",
       "3.0    0.350594\n",
       "2.0    0.318859\n",
       "4.0    0.176296\n",
       "5.0    0.114462\n",
       "1.0    0.039789\n",
       "Name: count, dtype: float64"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "strat_train_set['income_cat'].value_counts() / len(strat_train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "income_cat\n",
       "3.0    0.350533\n",
       "2.0    0.318798\n",
       "4.0    0.176357\n",
       "5.0    0.114341\n",
       "1.0    0.039971\n",
       "Name: count, dtype: float64"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "strat_test_set['income_cat'].value_counts() / len(strat_test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove a coluna nova, que foi adicionada apenas temporariamente.\n",
    "strat_train_set.drop(['income_cat'], axis=1, inplace=True)\n",
    "strat_test_set.drop(['income_cat'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 16512 entries, 12655 to 19773\n",
      "Data columns (total 10 columns):\n",
      " #   Column              Non-Null Count  Dtype  \n",
      "---  ------              --------------  -----  \n",
      " 0   longitude           16512 non-null  float64\n",
      " 1   latitude            16512 non-null  float64\n",
      " 2   housing_median_age  16512 non-null  float64\n",
      " 3   total_rooms         16512 non-null  float64\n",
      " 4   total_bedrooms      16354 non-null  float64\n",
      " 5   population          16512 non-null  float64\n",
      " 6   households          16512 non-null  float64\n",
      " 7   median_income       16512 non-null  float64\n",
      " 8   median_house_value  16512 non-null  float64\n",
      " 9   ocean_proximity     16512 non-null  object \n",
      "dtypes: float64(9), object(1)\n",
      "memory usage: 1.4+ MB\n"
     ]
    }
   ],
   "source": [
    "strat_train_set.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing = strat_train_set.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Criação da matriz de correlação, ajuda a ver o quanto uma variável implica na outra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>longitude</th>\n",
       "      <th>latitude</th>\n",
       "      <th>housing_median_age</th>\n",
       "      <th>total_rooms</th>\n",
       "      <th>total_bedrooms</th>\n",
       "      <th>population</th>\n",
       "      <th>households</th>\n",
       "      <th>median_income</th>\n",
       "      <th>median_house_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>longitude</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.924478</td>\n",
       "      <td>-0.105823</td>\n",
       "      <td>0.048909</td>\n",
       "      <td>0.076686</td>\n",
       "      <td>0.108071</td>\n",
       "      <td>0.063146</td>\n",
       "      <td>-0.019615</td>\n",
       "      <td>-0.047466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>latitude</th>\n",
       "      <td>-0.924478</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.005737</td>\n",
       "      <td>-0.039245</td>\n",
       "      <td>-0.072550</td>\n",
       "      <td>-0.115290</td>\n",
       "      <td>-0.077765</td>\n",
       "      <td>-0.075146</td>\n",
       "      <td>-0.142673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>housing_median_age</th>\n",
       "      <td>-0.105823</td>\n",
       "      <td>0.005737</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.364535</td>\n",
       "      <td>-0.325101</td>\n",
       "      <td>-0.298737</td>\n",
       "      <td>-0.306473</td>\n",
       "      <td>-0.111315</td>\n",
       "      <td>0.114146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_rooms</th>\n",
       "      <td>0.048909</td>\n",
       "      <td>-0.039245</td>\n",
       "      <td>-0.364535</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.929391</td>\n",
       "      <td>0.855103</td>\n",
       "      <td>0.918396</td>\n",
       "      <td>0.200133</td>\n",
       "      <td>0.135140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_bedrooms</th>\n",
       "      <td>0.076686</td>\n",
       "      <td>-0.072550</td>\n",
       "      <td>-0.325101</td>\n",
       "      <td>0.929391</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.876324</td>\n",
       "      <td>0.980167</td>\n",
       "      <td>-0.009643</td>\n",
       "      <td>0.047781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>population</th>\n",
       "      <td>0.108071</td>\n",
       "      <td>-0.115290</td>\n",
       "      <td>-0.298737</td>\n",
       "      <td>0.855103</td>\n",
       "      <td>0.876324</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.904639</td>\n",
       "      <td>0.002421</td>\n",
       "      <td>-0.026882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>households</th>\n",
       "      <td>0.063146</td>\n",
       "      <td>-0.077765</td>\n",
       "      <td>-0.306473</td>\n",
       "      <td>0.918396</td>\n",
       "      <td>0.980167</td>\n",
       "      <td>0.904639</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.010869</td>\n",
       "      <td>0.064590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>median_income</th>\n",
       "      <td>-0.019615</td>\n",
       "      <td>-0.075146</td>\n",
       "      <td>-0.111315</td>\n",
       "      <td>0.200133</td>\n",
       "      <td>-0.009643</td>\n",
       "      <td>0.002421</td>\n",
       "      <td>0.010869</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.687151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>median_house_value</th>\n",
       "      <td>-0.047466</td>\n",
       "      <td>-0.142673</td>\n",
       "      <td>0.114146</td>\n",
       "      <td>0.135140</td>\n",
       "      <td>0.047781</td>\n",
       "      <td>-0.026882</td>\n",
       "      <td>0.064590</td>\n",
       "      <td>0.687151</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    longitude  latitude  housing_median_age  total_rooms  \\\n",
       "longitude            1.000000 -0.924478           -0.105823     0.048909   \n",
       "latitude            -0.924478  1.000000            0.005737    -0.039245   \n",
       "housing_median_age  -0.105823  0.005737            1.000000    -0.364535   \n",
       "total_rooms          0.048909 -0.039245           -0.364535     1.000000   \n",
       "total_bedrooms       0.076686 -0.072550           -0.325101     0.929391   \n",
       "population           0.108071 -0.115290           -0.298737     0.855103   \n",
       "households           0.063146 -0.077765           -0.306473     0.918396   \n",
       "median_income       -0.019615 -0.075146           -0.111315     0.200133   \n",
       "median_house_value  -0.047466 -0.142673            0.114146     0.135140   \n",
       "\n",
       "                    total_bedrooms  population  households  median_income  \\\n",
       "longitude                 0.076686    0.108071    0.063146      -0.019615   \n",
       "latitude                 -0.072550   -0.115290   -0.077765      -0.075146   \n",
       "housing_median_age       -0.325101   -0.298737   -0.306473      -0.111315   \n",
       "total_rooms               0.929391    0.855103    0.918396       0.200133   \n",
       "total_bedrooms            1.000000    0.876324    0.980167      -0.009643   \n",
       "population                0.876324    1.000000    0.904639       0.002421   \n",
       "households                0.980167    0.904639    1.000000       0.010869   \n",
       "median_income            -0.009643    0.002421    0.010869       1.000000   \n",
       "median_house_value        0.047781   -0.026882    0.064590       0.687151   \n",
       "\n",
       "                    median_house_value  \n",
       "longitude                    -0.047466  \n",
       "latitude                     -0.142673  \n",
       "housing_median_age            0.114146  \n",
       "total_rooms                   0.135140  \n",
       "total_bedrooms                0.047781  \n",
       "population                   -0.026882  \n",
       "households                    0.064590  \n",
       "median_income                 0.687151  \n",
       "median_house_value            1.000000  "
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correlation_matrix = housing.drop(columns=['ocean_proximity']).corr()\n",
    "correlation_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Separando os dados entre variáveis indepedentes (as de entrada) e depedentes (de saída)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variáveis independentes: dataset original menos a coluna de valores dependentes.\n",
    "housing = strat_train_set.drop(\"median_house_value\", axis=1)\n",
    "\n",
    "# Variável dependente, também chamada de label.\n",
    "housing_labels = strat_train_set[\"median_house_value\"].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 16512 entries, 12655 to 19773\n",
      "Data columns (total 9 columns):\n",
      " #   Column              Non-Null Count  Dtype  \n",
      "---  ------              --------------  -----  \n",
      " 0   longitude           16512 non-null  float64\n",
      " 1   latitude            16512 non-null  float64\n",
      " 2   housing_median_age  16512 non-null  float64\n",
      " 3   total_rooms         16512 non-null  float64\n",
      " 4   total_bedrooms      16354 non-null  float64\n",
      " 5   population          16512 non-null  float64\n",
      " 6   households          16512 non-null  float64\n",
      " 7   median_income       16512 non-null  float64\n",
      " 8   ocean_proximity     16512 non-null  object \n",
      "dtypes: float64(8), object(1)\n",
      "memory usage: 1.3+ MB\n"
     ]
    }
   ],
   "source": [
    "housing.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preenchendo as colunas vazias do DataFrame utilizando o SimpleImputer.\n",
    "\n",
    "A estratégia utilizada é a \"median\", ou seja, o nosso imputer encontra as linhas vazias e coloca a mediana do valor no local."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transformadores no SKlearn\n",
    "\n",
    "- `fit(x)` : aprende a transformações (mean,median,most common, constant)\n",
    "- `transform(x)` : retorna o dataset transformado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "158\n",
      "Estatísticas do Imputer:\n",
      "[-118.51      34.26      29.      2119.       433.      1164.\n",
      "  408.         3.54155]\n",
      "Medianas\n",
      "[-118.51      34.26      29.      2119.       433.      1164.\n",
      "  408.         3.54155]\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'pandas.core.frame.DataFrame'>\n"
     ]
    }
   ],
   "source": [
    "sample_incomplete_rows = housing[housing.isnull().any(axis=1)]\n",
    "print(len(sample_incomplete_rows))\n",
    "\n",
    "# Cria um imputer que substitui células inválidas (NaN) pela mediana dos valores da coluna à qual a célula pertence.\n",
    "from sklearn.impute import SimpleImputer\n",
    "imputer = SimpleImputer(strategy='median')\n",
    "\n",
    "# Antes de treinar o SimpleImputer, remover a coluna de dados categóricos. O dataset resultante tem apenas\n",
    "# as variáveis independentes numéricas.\n",
    "housing_num = housing.drop(\"ocean_proximity\", axis=1)\n",
    "\n",
    "# Agora treinar o Imputer. Isto vai causar o cálculo da mediana de cada coluna, \n",
    "# que ficará armazenado no Imputer para uso futuro. \n",
    "imputer.fit(housing_num)\n",
    "\n",
    "# O Imputer agora tem as estatísticas desejadas armazenadas.\n",
    "print(\"Estatísticas do Imputer:\")\n",
    "print(imputer.statistics_)\n",
    "\n",
    "# Compare com as medianas do DataFrame:\n",
    "print(\"Medianas\")\n",
    "print(housing_num.median().values)\n",
    "\n",
    "# Aplicar o Imputer aos nossos dados. O valor de retorno é um ndarray do NumPy.\n",
    "temp = imputer.transform(housing_num)\n",
    "print(type(temp))\n",
    "\n",
    "# Trabalhar com DataFrames geralmente é mais legal - dá para referenciar colunas por nome, ao invés de indices.\n",
    "# Vamos transformar o ndarray em DataFrame.\n",
    "housing_tr = pd.DataFrame(temp, columns=housing_num.columns)\n",
    "print(type(housing_tr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verificação de colunas vazias no DataFrame Original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>longitude</th>\n",
       "      <th>latitude</th>\n",
       "      <th>housing_median_age</th>\n",
       "      <th>total_rooms</th>\n",
       "      <th>total_bedrooms</th>\n",
       "      <th>population</th>\n",
       "      <th>households</th>\n",
       "      <th>median_income</th>\n",
       "      <th>ocean_proximity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1606</th>\n",
       "      <td>-122.08</td>\n",
       "      <td>37.88</td>\n",
       "      <td>26.0</td>\n",
       "      <td>2947.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>825.0</td>\n",
       "      <td>626.0</td>\n",
       "      <td>2.9330</td>\n",
       "      <td>NEAR BAY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10915</th>\n",
       "      <td>-117.87</td>\n",
       "      <td>33.73</td>\n",
       "      <td>45.0</td>\n",
       "      <td>2264.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1970.0</td>\n",
       "      <td>499.0</td>\n",
       "      <td>3.4193</td>\n",
       "      <td>&lt;1H OCEAN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19150</th>\n",
       "      <td>-122.70</td>\n",
       "      <td>38.35</td>\n",
       "      <td>14.0</td>\n",
       "      <td>2313.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>954.0</td>\n",
       "      <td>397.0</td>\n",
       "      <td>3.7813</td>\n",
       "      <td>&lt;1H OCEAN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4186</th>\n",
       "      <td>-118.23</td>\n",
       "      <td>34.13</td>\n",
       "      <td>48.0</td>\n",
       "      <td>1308.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>835.0</td>\n",
       "      <td>294.0</td>\n",
       "      <td>4.2891</td>\n",
       "      <td>&lt;1H OCEAN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16885</th>\n",
       "      <td>-122.40</td>\n",
       "      <td>37.58</td>\n",
       "      <td>26.0</td>\n",
       "      <td>3281.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1145.0</td>\n",
       "      <td>480.0</td>\n",
       "      <td>6.3580</td>\n",
       "      <td>NEAR OCEAN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1350</th>\n",
       "      <td>-121.95</td>\n",
       "      <td>38.03</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5526.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3207.0</td>\n",
       "      <td>1012.0</td>\n",
       "      <td>4.0767</td>\n",
       "      <td>INLAND</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4691</th>\n",
       "      <td>-118.37</td>\n",
       "      <td>34.07</td>\n",
       "      <td>50.0</td>\n",
       "      <td>2519.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1117.0</td>\n",
       "      <td>516.0</td>\n",
       "      <td>4.3667</td>\n",
       "      <td>&lt;1H OCEAN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9149</th>\n",
       "      <td>-118.50</td>\n",
       "      <td>34.46</td>\n",
       "      <td>17.0</td>\n",
       "      <td>10267.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4956.0</td>\n",
       "      <td>1483.0</td>\n",
       "      <td>5.5061</td>\n",
       "      <td>&lt;1H OCEAN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16757</th>\n",
       "      <td>-122.48</td>\n",
       "      <td>37.70</td>\n",
       "      <td>33.0</td>\n",
       "      <td>4492.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3477.0</td>\n",
       "      <td>1537.0</td>\n",
       "      <td>3.0546</td>\n",
       "      <td>NEAR OCEAN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13336</th>\n",
       "      <td>-117.67</td>\n",
       "      <td>34.04</td>\n",
       "      <td>13.0</td>\n",
       "      <td>1543.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>776.0</td>\n",
       "      <td>358.0</td>\n",
       "      <td>3.0598</td>\n",
       "      <td>INLAND</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>158 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       longitude  latitude  housing_median_age  total_rooms  total_bedrooms  \\\n",
       "1606     -122.08     37.88                26.0       2947.0             NaN   \n",
       "10915    -117.87     33.73                45.0       2264.0             NaN   \n",
       "19150    -122.70     38.35                14.0       2313.0             NaN   \n",
       "4186     -118.23     34.13                48.0       1308.0             NaN   \n",
       "16885    -122.40     37.58                26.0       3281.0             NaN   \n",
       "...          ...       ...                 ...          ...             ...   \n",
       "1350     -121.95     38.03                 5.0       5526.0             NaN   \n",
       "4691     -118.37     34.07                50.0       2519.0             NaN   \n",
       "9149     -118.50     34.46                17.0      10267.0             NaN   \n",
       "16757    -122.48     37.70                33.0       4492.0             NaN   \n",
       "13336    -117.67     34.04                13.0       1543.0             NaN   \n",
       "\n",
       "       population  households  median_income ocean_proximity  \n",
       "1606        825.0       626.0         2.9330        NEAR BAY  \n",
       "10915      1970.0       499.0         3.4193       <1H OCEAN  \n",
       "19150       954.0       397.0         3.7813       <1H OCEAN  \n",
       "4186        835.0       294.0         4.2891       <1H OCEAN  \n",
       "16885      1145.0       480.0         6.3580      NEAR OCEAN  \n",
       "...           ...         ...            ...             ...  \n",
       "1350       3207.0      1012.0         4.0767          INLAND  \n",
       "4691       1117.0       516.0         4.3667       <1H OCEAN  \n",
       "9149       4956.0      1483.0         5.5061       <1H OCEAN  \n",
       "16757      3477.0      1537.0         3.0546      NEAR OCEAN  \n",
       "13336       776.0       358.0         3.0598          INLAND  \n",
       "\n",
       "[158 rows x 9 columns]"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "housing[housing.isnull().any(axis=1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verificação do DataFrame após o tratamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>longitude</th>\n",
       "      <th>latitude</th>\n",
       "      <th>housing_median_age</th>\n",
       "      <th>total_rooms</th>\n",
       "      <th>total_bedrooms</th>\n",
       "      <th>population</th>\n",
       "      <th>households</th>\n",
       "      <th>median_income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [longitude, latitude, housing_median_age, total_rooms, total_bedrooms, population, households, median_income]\n",
       "Index: []"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "housing_tr[housing_tr.isnull().any(axis=1)].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Realizando o encoding para variáveis categóricas do DataFrame.\n",
    "\n",
    "O OrdinalEncoder transforma variáveis categóricas em números, e você poder ver o que cada número significa usando o `ordinal_encoder.categories_`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.],\n",
       "       [4.],\n",
       "       [1.],\n",
       "       [4.],\n",
       "       [0.],\n",
       "       [3.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.]])"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "ordinal_encoder = OrdinalEncoder()\n",
    "\n",
    "housing_ocean_encoded = ordinal_encoder.fit_transform(housing[['ocean_proximity']])\n",
    "housing_ocean_encoded[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array(['<1H OCEAN', 'INLAND', 'ISLAND', 'NEAR BAY', 'NEAR OCEAN'],\n",
       "       dtype=object)]"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ordinal_encoder.categories_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Realizando o OneHotEncoding para as variáveis do DataFrame. Cria uma coluna específica para cada valor possível dentro da coluna original, onde booleanos são colocados para \"se uma instância é ou não a variável daquela coluna\", um vetor de features binárias.\n",
    "\n",
    "O One-Hot Encoding recebe uma classe e retorna um vetor de variáveis booleanas, chamadas de variáveis dummy.\n",
    "\n",
    "As colunas do nosso exemplo são ``'<1H OCEAN'``, ``'NEAR OCEAN'``, ``'INLAND'``, ``'NEAR BAY'`` e ``'ISLAND'``. Nesse caso, se o OneHotEncoder receber uma linha com ``'NEAR OCEAN'`` e retorna o seguinte vetor: $ [ \\begin{array}{cc} 0 & 1 & 0 & 0 & 0\\\\\\end{array} ] $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'scipy.sparse._csr.csr_matrix'>\n",
      "  (0, 1)\t1.0\n",
      "  (1, 4)\t1.0\n",
      "  (2, 1)\t1.0\n",
      "  (3, 4)\t1.0\n",
      "  (4, 0)\t1.0\n",
      "  (5, 3)\t1.0\n",
      "  (6, 0)\t1.0\n",
      "  (7, 0)\t1.0\n",
      "  (8, 0)\t1.0\n",
      "  (9, 0)\t1.0\n",
      "  (10, 1)\t1.0\n",
      "  (11, 0)\t1.0\n",
      "  (12, 1)\t1.0\n",
      "  (13, 1)\t1.0\n",
      "  (14, 4)\t1.0\n",
      "  (15, 0)\t1.0\n",
      "  (16, 0)\t1.0\n",
      "  (17, 0)\t1.0\n",
      "  (18, 3)\t1.0\n",
      "  (19, 0)\t1.0\n",
      "  (20, 1)\t1.0\n",
      "  (21, 3)\t1.0\n",
      "  (22, 1)\t1.0\n",
      "  (23, 0)\t1.0\n",
      "  (24, 1)\t1.0\n",
      "  :\t:\n",
      "  (16487, 1)\t1.0\n",
      "  (16488, 0)\t1.0\n",
      "  (16489, 4)\t1.0\n",
      "  (16490, 4)\t1.0\n",
      "  (16491, 1)\t1.0\n",
      "  (16492, 1)\t1.0\n",
      "  (16493, 0)\t1.0\n",
      "  (16494, 0)\t1.0\n",
      "  (16495, 0)\t1.0\n",
      "  (16496, 1)\t1.0\n",
      "  (16497, 0)\t1.0\n",
      "  (16498, 4)\t1.0\n",
      "  (16499, 0)\t1.0\n",
      "  (16500, 0)\t1.0\n",
      "  (16501, 1)\t1.0\n",
      "  (16502, 1)\t1.0\n",
      "  (16503, 1)\t1.0\n",
      "  (16504, 1)\t1.0\n",
      "  (16505, 0)\t1.0\n",
      "  (16506, 0)\t1.0\n",
      "  (16507, 0)\t1.0\n",
      "  (16508, 1)\t1.0\n",
      "  (16509, 0)\t1.0\n",
      "  (16510, 0)\t1.0\n",
      "  (16511, 1)\t1.0\n"
     ]
    }
   ],
   "source": [
    "# Cria o codificador.\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "encoder = OneHotEncoder(categories='auto')\n",
    "\n",
    "# Aprende a codificação e já aplica a mesma ao dataset fornecido. Todo transformador no sklearn\n",
    "# tem os métodos fit() para aprender a transformação, e transform() para aplicá-la.\n",
    "# O método fit_transform() faz os dois atos em sequência.\n",
    "housing_cat_1hot = encoder.fit_transform(housing[['ocean_proximity']])\n",
    "\n",
    "# O resultado da codificação é uma matriz esparsa em NumPy.\n",
    "print(type(housing_cat_1hot))\n",
    "print(housing_cat_1hot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1.]\n",
      " [0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1.]\n",
      " [1. 0. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "# Convertendo em matriz densa só para observar melhor:\n",
    "print(housing_cat_1hot.toarray()[:5])\n",
    "\n",
    "# Você poderia também ter usado sparse=False na criação do OneHotEncoder.\n",
    "\n",
    "arr = housing_cat_1hot.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array(['<1H OCEAN', 'INLAND', 'ISLAND', 'NEAR BAY', 'NEAR OCEAN'],\n",
       "       dtype=object)]"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder.categories_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utilizando o CombinedAttributesAdder para inicializar novas colunas no DataFrame, nesse caso cômodos por casas, população por número de casas e número de quartos por cômodos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>longitude</th>\n",
       "      <th>latitude</th>\n",
       "      <th>housing_median_age</th>\n",
       "      <th>total_rooms</th>\n",
       "      <th>total_bedrooms</th>\n",
       "      <th>population</th>\n",
       "      <th>households</th>\n",
       "      <th>median_income</th>\n",
       "      <th>ocean_proximity</th>\n",
       "      <th>rooms_per_household</th>\n",
       "      <th>population_per_household</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-121.46</td>\n",
       "      <td>38.52</td>\n",
       "      <td>29.0</td>\n",
       "      <td>3873.0</td>\n",
       "      <td>797.0</td>\n",
       "      <td>2237.0</td>\n",
       "      <td>706.0</td>\n",
       "      <td>2.1736</td>\n",
       "      <td>INLAND</td>\n",
       "      <td>5.485836</td>\n",
       "      <td>3.168555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-117.23</td>\n",
       "      <td>33.09</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5320.0</td>\n",
       "      <td>855.0</td>\n",
       "      <td>2015.0</td>\n",
       "      <td>768.0</td>\n",
       "      <td>6.3373</td>\n",
       "      <td>NEAR OCEAN</td>\n",
       "      <td>6.927083</td>\n",
       "      <td>2.623698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-119.04</td>\n",
       "      <td>35.37</td>\n",
       "      <td>44.0</td>\n",
       "      <td>1618.0</td>\n",
       "      <td>310.0</td>\n",
       "      <td>667.0</td>\n",
       "      <td>300.0</td>\n",
       "      <td>2.875</td>\n",
       "      <td>INLAND</td>\n",
       "      <td>5.393333</td>\n",
       "      <td>2.223333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-117.13</td>\n",
       "      <td>32.75</td>\n",
       "      <td>24.0</td>\n",
       "      <td>1877.0</td>\n",
       "      <td>519.0</td>\n",
       "      <td>898.0</td>\n",
       "      <td>483.0</td>\n",
       "      <td>2.2264</td>\n",
       "      <td>NEAR OCEAN</td>\n",
       "      <td>3.886128</td>\n",
       "      <td>1.859213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-118.7</td>\n",
       "      <td>34.28</td>\n",
       "      <td>27.0</td>\n",
       "      <td>3536.0</td>\n",
       "      <td>646.0</td>\n",
       "      <td>1837.0</td>\n",
       "      <td>580.0</td>\n",
       "      <td>4.4964</td>\n",
       "      <td>&lt;1H OCEAN</td>\n",
       "      <td>6.096552</td>\n",
       "      <td>3.167241</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  longitude latitude housing_median_age total_rooms total_bedrooms population  \\\n",
       "0   -121.46    38.52               29.0      3873.0          797.0     2237.0   \n",
       "1   -117.23    33.09                7.0      5320.0          855.0     2015.0   \n",
       "2   -119.04    35.37               44.0      1618.0          310.0      667.0   \n",
       "3   -117.13    32.75               24.0      1877.0          519.0      898.0   \n",
       "4    -118.7    34.28               27.0      3536.0          646.0     1837.0   \n",
       "\n",
       "  households median_income ocean_proximity rooms_per_household  \\\n",
       "0      706.0        2.1736          INLAND            5.485836   \n",
       "1      768.0        6.3373      NEAR OCEAN            6.927083   \n",
       "2      300.0         2.875          INLAND            5.393333   \n",
       "3      483.0        2.2264      NEAR OCEAN            3.886128   \n",
       "4      580.0        4.4964       <1H OCEAN            6.096552   \n",
       "\n",
       "  population_per_household  \n",
       "0                 3.168555  \n",
       "1                 2.623698  \n",
       "2                 2.223333  \n",
       "3                 1.859213  \n",
       "4                 3.167241  "
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "class CombinedAttributesAdder(BaseEstimator, TransformerMixin):\n",
    "    # column index\n",
    "    rooms_ix, bedrooms_ix, population_ix, household_ix = 3, 4, 5, 6\n",
    "    \n",
    "    def __init__(self, add_bedrooms_per_room=True):  # no *args or **kargs\n",
    "        self.add_bedrooms_per_room = add_bedrooms_per_room\n",
    "        \n",
    "    def fit(self, X, y=None):\n",
    "        return self  # nothing else to do\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "\n",
    "        # pega a coluna de rooms e a coluna de households e divide uma coluna pela outra, mas em np.array, gravando o resultado em outra variável\n",
    "        rooms_per_household = \\\n",
    "            X[:, CombinedAttributesAdder.rooms_ix] / X[:, CombinedAttributesAdder.household_ix]\n",
    "        \n",
    "        # pega a coluna de popuação e a coluna de households e divide uma coluna pela outra, mas em np.array, gravando o resultado em outra variável\n",
    "        population_per_household = \\\n",
    "            X[:, CombinedAttributesAdder.population_ix] / X[:, CombinedAttributesAdder.household_ix]\n",
    "\n",
    "\n",
    "        if self.add_bedrooms_per_room:\n",
    "            # pega a coluna de quartos (bedrooms) e a coluna de cômodos e divide uma coluna pela outra, mas em np.array, e grava o resultado em outra variável\n",
    "            bedrooms_per_room = \\\n",
    "                X[:, CombinedAttributesAdder.bedrooms_ix] / X[:, CombinedAttributesAdder.rooms_ix]\n",
    "            \n",
    "            # retorna o array com as novas colunas adicionadas (concatenadas)\n",
    "            return np.c_[X, rooms_per_household, population_per_household, bedrooms_per_room]\n",
    "        else:\n",
    "            # retorna o array com as novas colunas adicionadas (concatenadas)\n",
    "            return np.c_[X, rooms_per_household, population_per_household]\n",
    "\n",
    "\n",
    "attr_adder = CombinedAttributesAdder(add_bedrooms_per_room=False)\n",
    "\n",
    "# montando o adder\n",
    "housing_extra_attribs = attr_adder.transform(housing.values)\n",
    "\n",
    "# Transformando em DataFrame, porque DataFrames são mais amigáveis.\n",
    "columns_housing_extra_attribs = list(housing.columns) + [\"rooms_per_household\", \"population_per_household\"]\n",
    "housing_extra_attribs = pd.DataFrame(housing_extra_attribs, columns=columns_housing_extra_attribs)\n",
    "housing_extra_attribs.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Criação de uma Pipeline simples, onde preenchemos as lacunas do DataFrame utilizando a estratégia da mediana, depois fazemos o input das nova colunas desejadas e dpois utilizamos o StandarScaler para normalizar os dados (remover a média e dividir pelo desvio padrão)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.94135046,  1.34743822,  0.02756357, ...,  0.01739526,\n",
       "         0.00622264, -0.12112176],\n",
       "       [ 1.17178212, -1.19243966, -1.72201763, ...,  0.56925554,\n",
       "        -0.04081077, -0.81086696],\n",
       "       [ 0.26758118, -0.1259716 ,  1.22045984, ..., -0.01802432,\n",
       "        -0.07537122, -0.33827252],\n",
       "       ...,\n",
       "       [-1.5707942 ,  1.31001828,  1.53856552, ..., -0.5092404 ,\n",
       "        -0.03743619,  0.32286937],\n",
       "       [-1.56080303,  1.2492109 , -1.1653327 , ...,  0.32814891,\n",
       "        -0.05915604, -0.45702273],\n",
       "       [-1.28105026,  2.02567448, -0.13148926, ...,  0.01407228,\n",
       "         0.00657083, -0.12169672]])"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Pipeline é uma cadeia de transformações, que rola um fit transform entre cada item da lista de transformações, alterando o DF original entre as etapas (o resultado de uma sendo a entrada da outra)\n",
    "num_pipeline = Pipeline([\n",
    "        ('imputer', SimpleImputer(strategy=\"median\")),\n",
    "        ('attribs_adder', CombinedAttributesAdder()),\n",
    "\n",
    "        # o StandardScaler remove a média de cada coluna e a divide pelo desvio padrão\n",
    "        ('std_scaler', StandardScaler()),\n",
    "    ])\n",
    "\n",
    "housing_num_tr = num_pipeline.fit_transform(housing_num)\n",
    "housing_num_tr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pipelina apenas utilizada para a Realização do OneHotEncoding na coluna de variáveis categóricas do DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jalfr\\Desktop\\Machine Learning\\aula_02_03\\env\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:972: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0., 1., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 1.],\n",
       "       [0., 1., 0., 0., 0.],\n",
       "       ...,\n",
       "       [1., 0., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0.]])"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_pipeline = Pipeline([\n",
    "        ('cat_encoder', OneHotEncoder(sparse=False)),\n",
    "    ])\n",
    "\n",
    "housing_cat_tr = cat_pipeline.fit_transform(housing[['ocean_proximity']])\n",
    "housing_cat_tr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O ColumnTransformer é como se fosse uma pipeline, recebe uma lista de operações com os tranformadores que você vai querer aplicar, mas por colunas.\n",
    "\n",
    "Você escolhe quais colunas que passam por cada transformador, e as não especificadas passam reto pelo processo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jalfr\\Desktop\\Machine Learning\\aula_02_03\\env\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:972: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "num_attribs = list(housing_num)\n",
    "cat_attribs = [\"ocean_proximity\"]\n",
    "\n",
    "full_pipeline = ColumnTransformer([\n",
    "        (\"num\", num_pipeline, num_attribs),\n",
    "        (\"cat\", OneHotEncoder(sparse=False), cat_attribs),\n",
    "    ])\n",
    "\n",
    "housing_prepared = full_pipeline.fit_transform(housing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Abaixo, temos o resultado final da pipeline no DataFrame antigo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jalfr\\Desktop\\Machine Learning\\aula_02_03\\env\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:972: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[-0.94135046,  1.34743822,  0.02756357,  0.58477745,  0.64037127,\n",
       "         0.73260236,  0.55628602, -0.8936472 ,  0.01739526,  0.00622264,\n",
       "        -0.12112176,  0.        ,  1.        ,  0.        ,  0.        ,\n",
       "         0.        ],\n",
       "       [ 1.17178212, -1.19243966, -1.72201763,  1.26146668,  0.78156132,\n",
       "         0.53361152,  0.72131799,  1.292168  ,  0.56925554, -0.04081077,\n",
       "        -0.81086696,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         1.        ],\n",
       "       [ 0.26758118, -0.1259716 ,  1.22045984, -0.46977281, -0.54513828,\n",
       "        -0.67467519, -0.52440722, -0.52543365, -0.01802432, -0.07537122,\n",
       "        -0.33827252,  0.        ,  1.        ,  0.        ,  0.        ,\n",
       "         0.        ],\n",
       "       [ 1.22173797, -1.35147437, -0.37006852, -0.34865152, -0.03636724,\n",
       "        -0.46761716, -0.03729672, -0.86592882, -0.59513997, -0.10680295,\n",
       "         0.96120521,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         1.        ],\n",
       "       [ 0.43743108, -0.63581817, -0.13148926,  0.42717947,  0.27279028,\n",
       "         0.37406031,  0.22089846,  0.32575178,  0.2512412 ,  0.00610923,\n",
       "        -0.47451338,  1.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ]])"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "housing_prepared = full_pipeline.fit_transform(housing)\n",
    "housing_prepared[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utilizando o modelo de regressão linear com as variaváveis independentes e depedentes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelos Preditivos do SciKitLearn tem apenas duas funções:\n",
    "\n",
    "- `fit(x,y)`: faz o treinamento do modelo\n",
    "- `predict(x)`: retorna a previsão de $y_{est}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variável dependente, também chamada de label.\n",
    "housing_labels = strat_train_set[\"median_house_value\"].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-4 {color: black;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" checked><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearRegression</label><div class=\"sk-toggleable__content\"><pre>LinearRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "lin_reg = LinearRegression()\n",
    "\n",
    "# fit é o que treina o modelo\n",
    "lin_reg.fit(housing_prepared, housing_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Um teste com o Regressor Linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predição: [ 85657.90192014 305492.60737488 152056.46122456 186095.70946094\n",
      " 244550.67966089]\n",
      "Original: [ 72100. 279600.  82700. 112500. 238300.]\n"
     ]
    }
   ],
   "source": [
    "# Seleciona 5 pontos do conjunto de treinamento.\n",
    "some_data = housing.iloc[:5]\n",
    "some_labels = housing_labels.iloc[:5]\n",
    "\n",
    "# Prepara os dados - não se esqueça deste passo.\n",
    "some_data_prepared = full_pipeline.transform(some_data)\n",
    "\n",
    "# Para obter as previsões, basta chamar o método predict()\n",
    "predicted_labels = lin_reg.predict(some_data_prepared)\n",
    "print(\"Predição: {}\".format(predicted_labels))\n",
    "\n",
    "# Compare com os valores originais:\n",
    "print(\"Original: {}\".format(some_labels.values))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Treinando o modelo preditivo e medindo o erro quadrático médio do seu resultado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Regressão linear: RMSE = 68627.87\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "housing_predictions = lin_reg.predict(housing_prepared)\n",
    "lin_mse = mean_squared_error(housing_labels, housing_predictions)\n",
    "lin_rmse = np.sqrt(lin_mse)\n",
    "print('Regressão linear: RMSE = {:.2f}'.format(lin_rmse))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Treinando o modelo preditivo de classificação por árvore de decisão"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-5 {color: black;}#sk-container-id-5 pre{padding: 0;}#sk-container-id-5 div.sk-toggleable {background-color: white;}#sk-container-id-5 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-5 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-5 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-5 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-5 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-5 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-5 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-5 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-5 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-5 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-5 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-5 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-5 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-5 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-5 div.sk-item {position: relative;z-index: 1;}#sk-container-id-5 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-5 div.sk-item::before, #sk-container-id-5 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-5 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-5 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-5 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-5 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-5 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-5 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-5 div.sk-label-container {text-align: center;}#sk-container-id-5 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-5 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-5\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>DecisionTreeRegressor(random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" checked><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeRegressor</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeRegressor(random_state=42)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "DecisionTreeRegressor(random_state=42)"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "tree_reg = DecisionTreeRegressor(random_state=RANDOM_SEED)\n",
    "tree_reg.fit(housing_prepared, housing_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predição: [ 72100. 279600.  82700. 112500. 238300.]\n",
      "Original: [ 72100. 279600.  82700. 112500. 238300.]\n"
     ]
    }
   ],
   "source": [
    "predicted_labels = tree_reg.predict(some_data_prepared)\n",
    "print(\"Predição: {}\".format(predicted_labels))\n",
    "print(\"Original: {}\".format(some_labels.values))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testando o erro quadrático médio do algoritmo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Regressão linear: RMSE = 0.00\n"
     ]
    }
   ],
   "source": [
    "housing_predictions = tree_reg.predict(housing_prepared)\n",
    "tree_mse = mean_squared_error(housing_labels, housing_predictions)\n",
    "tree_rmse = np.sqrt(tree_mse)\n",
    "print('Regressão linear: RMSE = {:.2f}'.format(tree_rmse))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Erro é 0, portanto, ocorreu o processo de OverFitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Realização de um Train/Test split: treinamos com um set de dados, e testamos a sua acuráia com outro. Neste caso, estamos criando um X de validação e um Y de validação, para que nossos modelos estejam de boa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_valid, y_train, y_valid = train_test_split(housing_prepared, housing_labels, test_size=0.2, random_state=RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Regressão Linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Regressão Linear: RMSE = 67700.15\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "lin_reg = LinearRegression()\n",
    "\n",
    "lin_reg.fit(X_train, y_train)\n",
    "\n",
    "y_pred = lin_reg.predict(X_valid)\n",
    "lin_rmse = np.sqrt(mean_squared_error(y_valid, y_pred))\n",
    "print('Regressão Linear: RMSE = {:.2f}'.format(lin_rmse))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Árvore de Decisão"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Regressão por Ávore de Decisão: RMSE = 72649.69\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "tree_reg = DecisionTreeRegressor(random_state=RANDOM_SEED)\n",
    "\n",
    "tree_reg.fit(X_train, y_train)\n",
    "\n",
    "y_pred = tree_reg.predict(X_valid)\n",
    "tree_rmse = np.sqrt(mean_squared_error(y_valid, y_pred))\n",
    "print('Regressão por Ávore de Decisão: RMSE = {:.2f}'.format(tree_rmse))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Regressão de Random Forest (várias árvores de classificação)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Regressão random forest: RMSE = 52413.54\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "forest_reg = RandomForestRegressor(n_estimators=10, random_state=RANDOM_SEED)\n",
    "\n",
    "forest_reg.fit(X_train, y_train)\n",
    "\n",
    "y_pred = forest_reg.predict(X_valid)\n",
    "forest_rmse = np.sqrt(mean_squared_error(y_valid, y_pred))\n",
    "print('Regressão random forest: RMSE = {:.2f}'.format(forest_rmse))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parece que o random forest é melhor que os outros!\n",
    "\n",
    "Mas talvez todos esses resultados sejam pura sorte: como saber? Podemos repetir esses experimentos com partições diferentes e ver se o resultado se mantém. O scikit-learn já tem ferramentas para ajudar nessa tarefa:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O código abaixo executa ***n-fold cross validation*** (neste caso, $n=10$). A função ``cross_val_score`` divide o conjunto de treinamento em $n$ partes e executa o procedimento de testes (treinar modelo, prever, medir erro) $n$ vezes - uma para cada partição. A cada ensaio a partição da vez é separada como conjunto de teste, e as demais compõe o conjunto de treinamento.\n",
    "\n",
    "Uma vantagem desta abordagem é que agora podemos ver a faixa de desempenhos do modelo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Validação Cruzada: quando fazemos a separação Treino/Validação/Teste, dividimos o nosso DataSet de treinamento e dividimos ele em dois pedaços ($x_{treino}$ e $x_{validacão}$). Na validação Cruzada, pegamos a metade de validação e testes e dividimos em um número ainda menor de pedaços, e realizamos treinamento e validação nesses pedaços da seguinte maneira: escolher um pedaço de teste (final) e treinar o modelo com os pedaços restantes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelo de Validação Cruzada aplicada a regressão linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores: [71762.76364394 64114.99166359 67771.17124356 68635.19072082\n",
      " 66846.14089488 72528.03725385 73997.08050233 68802.33629334\n",
      " 66443.28836884 70139.79923956]\n",
      "Mean: 69104.07998247063\n",
      "Standard deviation: 2880.328209818065\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "lin_scores = cross_val_score(lin_reg, housing_prepared, housing_labels, scoring=\"neg_mean_squared_error\", cv=10)\n",
    "lin_rmse_scores = np.sqrt(-lin_scores)\n",
    "\n",
    "\n",
    "def display_scores(scores):\n",
    "    print(\"Scores:\", scores)\n",
    "    print(\"Mean:\", scores.mean())\n",
    "    print(\"Standard deviation:\", scores.std())\n",
    "\n",
    "display_scores(lin_rmse_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aplicado ao Random Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores: [72831.45749112 69973.18438322 69528.56551415 72517.78229792\n",
      " 69145.50006909 79094.74123727 68960.045444   73344.50225684\n",
      " 69826.02473916 71077.09753998]\n",
      "Mean: 71629.89009727491\n",
      "Standard deviation: 2914.035468468928\n"
     ]
    }
   ],
   "source": [
    "tree_scores = cross_val_score(tree_reg, housing_prepared, housing_labels, scoring=\"neg_mean_squared_error\", cv=10)\n",
    "tree_rmse_scores = np.sqrt(-tree_scores)\n",
    "display_scores(tree_rmse_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparação de TTest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TtestResult(statistic=-1.8493701883396976, pvalue=0.08089762185936315, df=17.997563986491905)"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.stats import ttest_ind\n",
    "\n",
    "# alpha é geralmento 0.05\n",
    "# para afirmar que a hipótese nula está errada, tem que avaliar o pvalue e ver se ele é menor que o valor de alpha escolhido\n",
    "\n",
    "# In statistical hypothesis testing, the p-value serves as an alternative to rejection points to provide the smallest level of significance at which the null hypothesis would be rejected. \n",
    "# The p-value is the probability of obtaining results at least as extreme as the observed results of a statistical hypothesis test, assuming that the null hypothesis is correct. \n",
    "# A smaller p-value means that there is stronger evidence in favor of the alternative hypothesis.\n",
    "\n",
    "# If the p-value is less than or equal to the significance level, reject the null hypothesis in favor of the alternative hypothesis.\n",
    "# However, the risk of rejecting the null hypothesis is often higher than the p-value, especially when looking at a single study or when using small sample sizes.\n",
    "# The choice of significance level at which you reject H0 is arbitrary, with conventionally the 5%, 1%, and 0.1% levels used.1\n",
    "\n",
    "\n",
    "ttest_ind(lin_rmse_scores,tree_rmse_scores,equal_var=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aplicado ao Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores: [53519.05518628 50467.33817051 48924.16513902 53771.72056856\n",
      " 50810.90996358 54876.09682033 56012.79985518 52256.88927227\n",
      " 51527.73185039 55762.56008531]\n",
      "Mean: 52792.92669114079\n",
      "Standard deviation: 2262.8151900582\n"
     ]
    }
   ],
   "source": [
    "forest_scores = cross_val_score(forest_reg, housing_prepared, housing_labels, scoring=\"neg_mean_squared_error\", cv=10, n_jobs=-1)\n",
    "forest_rmse_scores = np.sqrt(-forest_scores)\n",
    "display_scores(forest_rmse_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TtestResult(statistic=13.359318769367425, pvalue=1.8498893257958064e-10, df=17.044881939960536)"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.stats import ttest_ind\n",
    "\n",
    "# alpha é geralmento 0.05\n",
    "# para afirmar que a hipótese nula está errada, tem que avaliar o pvalue e ver se ele é menor que o valor de alpha escolhido\n",
    "\n",
    "# In statistical hypothesis testing, the p-value serves as an alternative to rejection points to provide the smallest level of significance at which the null hypothesis would be rejected. \n",
    "# The p-value is the probability of obtaining results at least as extreme as the observed results of a statistical hypothesis test, assuming that the null hypothesis is correct. \n",
    "# A smaller p-value means that there is stronger evidence in favor of the alternative hypothesis.\n",
    "\n",
    "# If the p-value is less than or equal to the significance level, reject the null hypothesis in favor of the alternative hypothesis.\n",
    "# However, the risk of rejecting the null hypothesis is often higher than the p-value, especially when looking at a single study or when using small sample sizes.\n",
    "# The choice of significance level at which you reject H0 is arbitrary, with conventionally the 5%, 1%, and 0.1% levels used.1\n",
    "\n",
    "\n",
    "ttest_ind(lin_rmse_scores,forest_rmse_scores,equal_var=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mas afinal, o que é um modelo de regressão? É uma função que transforma os dados de entrada em um valor de saída, e que também pode depender de alguns **parâmetros**:\n",
    "\n",
    "$$y = h(x; \\theta)$$\n",
    "\n",
    "Treinar o modelo é ajustar os parâmetros do modelo para maximizar o desempenho preditivo deste. Para tanto devemos usar um algoritmo de treinamento. Cada classe de modelos demanda seu próprio algoritmo de treinamento, vamos estudar isso em detalhes mais tarde.\n",
    "\n",
    "$$\\theta_{opt} = \\text{argmin}_{\\theta} \\{ \\text{RMSE}\\left(X_{\\text{train}}, y_{\\text{train}}, h_{\\theta} \\right) \\}$$\n",
    "\n",
    "Plot twist: os algoritmos de treinamento em si *também* tem seus parâmetros! Ademais, os modelos tem parâmetros que especificam sub-classes de modelos, e diferem dos parâmetros voltados ao \"ajuste fino\". A esses meta-parâmetros chamamos **hiperparâmetros**.\n",
    "\n",
    "Os parâmetros regulares são ajustados pelo método ``fit()`` dos regressores. Como ajustar os hiperparâmetros? A abordagem mais simples é testar vários valores e ver o que funciona! Existem abordagens mais sofisticadas, que discutiremos depois, mas por hoje vamos testar uma dessas abordagens \"força-bruta\" chamada *grid search*.\n",
    "\n",
    "Funciona assim: escolha alguns valores possíveis de hiperparâmetros, e teste todas as combinações. Vamos aplicar isso ao regressor random forest. Não se preocupe com o significado destes hiperparâmetros por enquanto, vamos estudar isso em detalhes depois.\n",
    "\n",
    "Em scikit-learn, temos uma classe ``GridSearchCV`` para fazer isso. *AVISO*: vai demorar!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tempo gasto: 39.16 s\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from timeit import default_timer\n",
    "\n",
    "# lista de experimentos (nome do hiperparâmetro e opções que quer testar)\n",
    "param_grid = [\n",
    "    # try 6 (2×3) combinations of hyperparameters\n",
    "    {'n_estimators': [10, 30], 'max_features': [4, 6, 8]},\n",
    "    # then try 4 (1x2×2) combinations with bootstrap set as False\n",
    "    {'bootstrap': [False], 'n_estimators': [3, 10], 'max_features': [3, 4]},\n",
    "  ]\n",
    "\n",
    "forest_reg = RandomForestRegressor(random_state=RANDOM_SEED)\n",
    "\n",
    "# train across 5 folds, that's a total of (6+4)*5=50 rounds of training \n",
    "grid_search = GridSearchCV(forest_reg, param_grid, cv=5, scoring='neg_mean_squared_error', return_train_score=True, n_jobs=-1)\n",
    "\n",
    "t1 = default_timer()\n",
    "grid_search.fit(housing_prepared, housing_labels)\n",
    "t2 = default_timer()\n",
    "\n",
    "print(f'Tempo gasto: {t2 - t1:.2f} s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_features': 8, 'n_estimators': 30}"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O ``GridSearch`` já retorna o melhor modelo treinado:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-7 {color: black;}#sk-container-id-7 pre{padding: 0;}#sk-container-id-7 div.sk-toggleable {background-color: white;}#sk-container-id-7 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-7 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-7 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-7 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-7 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-7 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-7 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-7 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-7 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-7 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-7 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-7 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-7 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-7 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-7 div.sk-item {position: relative;z-index: 1;}#sk-container-id-7 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-7 div.sk-item::before, #sk-container-id-7 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-7 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-7 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-7 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-7 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-7 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-7 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-7 div.sk-label-container {text-align: center;}#sk-container-id-7 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-7 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-7\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestRegressor(max_features=8, n_estimators=30, random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" checked><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestRegressor</label><div class=\"sk-toggleable__content\"><pre>RandomForestRegressor(max_features=8, n_estimators=30, random_state=42)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestRegressor(max_features=8, n_estimators=30, random_state=42)"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para alguns modelos de machine learning podemos obter a importância relativa das características no processo de predição. Esta informação é importante para entender melhor nosso problema. De fato, um dos usos bastante importantes do machine learning é exatamente isso: usar o machine learning para entender melhor o problema em si!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([6.96542523e-02, 6.04213840e-02, 4.21882202e-02, 1.52450557e-02,\n",
       "       1.55545295e-02, 1.58491147e-02, 1.49346552e-02, 3.79009225e-01,\n",
       "       5.47789150e-02, 1.07031322e-01, 4.82031213e-02, 6.79266007e-03,\n",
       "       1.65706303e-01, 7.83480660e-05, 1.52473276e-03, 3.02816106e-03])"
      ]
     },
     "execution_count": 421,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_importances = grid_search.best_estimator_.feature_importances_\n",
    "feature_importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.3790092248170967, 'median_income'),\n",
       " (0.16570630316895876, 'INLAND'),\n",
       " (0.10703132208204355, 'pop_per_hhold'),\n",
       " (0.06965425227942929, 'longitude'),\n",
       " (0.0604213840080722, 'latitude'),\n",
       " (0.054778915018283726, 'rooms_per_hhold'),\n",
       " (0.048203121338269206, 'bedrooms_per_room'),\n",
       " (0.04218822024391753, 'housing_median_age'),\n",
       " (0.015849114744428634, 'population'),\n",
       " (0.015554529490469328, 'total_bedrooms'),\n",
       " (0.01524505568840977, 'total_rooms'),\n",
       " (0.014934655161887772, 'households'),\n",
       " (0.006792660074259966, '<1H OCEAN'),\n",
       " (0.0030281610628962747, 'NEAR OCEAN'),\n",
       " (0.0015247327555504937, 'NEAR BAY'),\n",
       " (7.834806602687504e-05, 'ISLAND')]"
      ]
     },
     "execution_count": 423,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extra_attribs = [\"rooms_per_hhold\", \"pop_per_hhold\", \"bedrooms_per_room\"]\n",
    "cat_encoder = cat_pipeline.named_steps[\"cat_encoder\"]\n",
    "cat_one_hot_attribs = list(cat_encoder.categories_[0])\n",
    "attributes = num_attribs + extra_attribs + cat_one_hot_attribs\n",
    "sorted(zip(feature_importances, attributes), reverse=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Usamos validação cruzada para achar a melhor família de regressores para nosso modelo. Note que nesta etapa não ajustamos hiperparâmetros, apenas confiamos nos valores default.\n",
    "\n",
    "- Usamos novamente validação cruzada para achar os melhores hiperparâmetros, com busca no espaço de hiperparâmetros.\n",
    "\n",
    "Agora temos o nosso melhor modelo, treinado na forja da validação cruzada! Chegou finalmente a hora de medir o desempenho do regressor no conjunto de testes!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE = 47873.26095812988\n"
     ]
    }
   ],
   "source": [
    "final_model = grid_search.best_estimator_\n",
    "\n",
    "X_test = strat_test_set.drop(\"median_house_value\", axis=1)\n",
    "y_test = strat_test_set[\"median_house_value\"].copy()\n",
    "\n",
    "X_test_prepared = full_pipeline.transform(X_test)\n",
    "final_predictions = final_model.predict(X_test_prepared)\n",
    "\n",
    "final_mse = mean_squared_error(y_test, final_predictions)\n",
    "final_rmse = np.sqrt(final_mse)\n",
    "\n",
    "print(\"RMSE = {}\".format(final_rmse))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
